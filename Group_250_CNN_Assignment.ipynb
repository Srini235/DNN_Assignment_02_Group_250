{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a720c98b",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Srini235/CV_Assignment_02_Group143/blob/main/CV_assignment2_Group143_PS4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c0d0f",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "**Course Deep Neural Networks (S1-25_AIMLCZG511) Assignment 2 - BITS Pilani - Group 143**\n",
    "\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "  <img src=\"https://th.bing.com/th/id/R.dad30338482f639dfd195fc9edff44d5?rik=XbcXpbagmBBREQ&riu=http%3a%2f%2fcoursera-university-assets.s3.amazonaws.com%2fb9%2fc608c79b5c498a8fa55b117fc3282f%2f5.-Square-logo-for-landing-page---Alpha.png&ehk=zzXfrWqRyL2OO90JGSlPDnlDFD2CAwKefaN%2bhuEyhT8%3d&risl=&pid=ImgRaw&r=0\" width=\"300\" height=\"300\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb280a81",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "DEEP NEURAL NETWORKS - ASSIGNMENT 2: CNN FOR IMAGE CLASSIFICATION\n",
    "Convolutional Neural Networks: Custom Implementation vs Transfer Learning\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64cf81",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "STUDENT INFORMATION (REQUIRED - DO NOT DELETE)\n",
    "================================================================================\n",
    "\n",
    "**Student Name:** Srinivasan R  \n",
    "**Student ID:** 2024AC05744  \n",
    "\n",
    "**Student Name:** Manodhayan K  \n",
    "**Student ID:** 2024AC05643 \n",
    "\n",
    "**Student Name:** Ankit Saxena  \n",
    "**Student ID:** 2024AC05902  \n",
    "\n",
    "**Student Name:** Vinu Abinayaa R  \n",
    "**Student ID:** 2024AC05772\n",
    "\n",
    "**Date:** 27-12-2025\n",
    "\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07deef",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "ASSIGNMENT OVERVIEW\n",
    "================================================================================\n",
    "\n",
    "This assignment requires you to implement and compare two CNN approaches for\n",
    "image classification:\n",
    "1. Custom CNN architecture using Keras/PyTorch\n",
    "2. Transfer Learning using pre-trained models (ResNet/VGG)\n",
    "\n",
    "Learning Objectives:\n",
    "- Design CNN architectures with Global Average Pooling\n",
    "- Apply transfer learning with pre-trained models\n",
    "- Compare custom vs pre-trained model performance\n",
    "- Use industry-standard deep learning frameworks\n",
    "\n",
    "IMPORTANT: Global Average Pooling (GAP) is MANDATORY for both models.\n",
    "DO NOT use Flatten + Dense layers in the final architecture.\n",
    "\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0c34d",
   "metadata": {
    "id": "7fe0c34d"
   },
   "source": [
    "================================================================================\n",
    "⚠️ IMPORTANT SUBMISSION REQUIREMENTS - STRICTLY ENFORCED ⚠️\n",
    "================================================================================\n",
    "\n",
    "1. FILENAME FORMAT: <BITS_ID>_cnn_assignment.ipynb\n",
    "   Example: 2025AA05036_cnn_assignment.ipynb\n",
    "   ❌ Wrong filename = Automatic 0 marks\n",
    "\n",
    "2. STUDENT INFORMATION MUST MATCH:\n",
    "   ✓ BITS ID in filename = BITS ID in notebook (above)\n",
    "   ✓ Name in folder = Name in notebook (above)\n",
    "   ❌ Mismatch = 0 marks\n",
    "\n",
    "3. EXECUTE ALL CELLS BEFORE SUBMISSION:\n",
    "   - Run: Kernel → Restart & Run All\n",
    "   - Verify all outputs are visible\n",
    "   ❌ No outputs = 0 marks\n",
    "\n",
    "4. FILE INTEGRITY:\n",
    "   - Ensure notebook opens without errors\n",
    "   - Check for corrupted cells\n",
    "   ❌ Corrupted file = 0 marks\n",
    "\n",
    "5. GLOBAL AVERAGE POOLING (GAP) MANDATORY:\n",
    "   - Both custom CNN and transfer learning must use GAP\n",
    "   - DO NOT use Flatten + Dense layers\n",
    "   ❌ Using Flatten+Dense = 0 marks for that model\n",
    "\n",
    "6. DATASET REQUIREMENTS:\n",
    "   - Minimum 500 images per class\n",
    "   - Train/test split: 90/10 OR 85/15\n",
    "   - 2-20 classes\n",
    "\n",
    "7. USE KERAS OR PYTORCH:\n",
    "   - Use standard model.fit() or training loops\n",
    "   - Do NOT implement convolution from scratch\n",
    "\n",
    "8. FILE SUBMISSION:\n",
    "   - Submit ONLY the .ipynb file\n",
    "   - NO zip files, NO separate data files, NO separate image files\n",
    "   - All code and outputs must be in the notebook\n",
    "   - Only one submission attempt allowed\n",
    "\n",
    "================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b70a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12223,
     "status": "ok",
     "timestamp": 1770835902903,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "8f7b70a5",
    "outputId": "7a8d5942-7ee7-4fc5-c40d-ac1a49df9a5e"
   },
   "outputs": [],
   "source": [
    "!pip install pandas seaborn torch torchvision pillow opencv-python scikit-learn tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058ef17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25973,
     "status": "ok",
     "timestamp": 1770835928891,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "0058ef17",
    "outputId": "3defc453-2db9-4918-fb09-e75bb3afc509"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os, sys, time, json, random, shutil, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Deep learning frameworks (choose Keras or PyTorch)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('PyTorch:', torch.__version__)\n",
    "\n",
    "# For image processing\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# For metric calculation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# TensorBoard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "ROOT = '/content' if Path('/content').exists() else os.getcwd()\n",
    "LOG_DIR = os.path.join(ROOT, 'logs')\n",
    "shutil.rmtree(LOG_DIR, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d771a",
   "metadata": {
    "id": "bc0d771a"
   },
   "source": [
    "================================================================================\n",
    "PART 1: DATASET LOADING AND EXPLORATION (Informational)\n",
    "================================================================================\n",
    "\n",
    "Instructions:\n",
    "1. Choose ONE dataset from the allowed list\n",
    "2. Load and explore the data\n",
    "3. Fill in ALL required metadata fields below\n",
    "4. Provide justification for your primary metric choice\n",
    "\n",
    "ALLOWED DATASETS:\n",
    "- Cats vs Dogs (2 classes)\n",
    "- Food-101 subset (10-20 classes)\n",
    "- Plant Disease (3-5 classes)\n",
    "- Medical Images (2-3 classes)\n",
    "- Custom dataset (with IC approval, min 500 images per class)\n",
    "\n",
    "REQUIRED OUTPUT:\n",
    "- Print all metadata fields\n",
    "- Brief EDA with visualizations\n",
    "- Data distribution analysis\n",
    "\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95007911",
   "metadata": {
    "id": "95007911"
   },
   "source": [
    "## 1.1 Dataset Selection and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030cad9",
   "metadata": {
    "id": "1030cad9"
   },
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a72a99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65041,
     "status": "ok",
     "timestamp": 1770835993934,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "27a72a99",
    "outputId": "d033669f-a1ef-4298-be92-e7ace24d470f"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(ROOT, 'data')\n",
    "SRC_DIR = os.path.join(DATA_DIR, 'PlantVillage-Dataset')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "if Path(os.path.join(SRC_DIR, '.git')).exists():\n",
    "    print('[Skip] Repo already present at', SRC_DIR)\n",
    "else:\n",
    "    print('[Clone] Fetching PlantVillage mirror ...')\n",
    "    !git clone --depth 1 https://github.com/gabrieldgf4/PlantVillage-Dataset.git \"$SRC_DIR\"\n",
    "print('[Sanity] Tomato classes:')\n",
    "!ls -1 \"$SRC_DIR\" | grep -E '^Tomato' | sort | sed 's/^/ - /'\n",
    "\n",
    "SRC_DIR = os.path.join(DATA_DIR, 'PlantVillage-Dataset')\n",
    "TOMATO_DIR = os.path.join(DATA_DIR, 'tomato_full')\n",
    "if Path(TOMATO_DIR).exists() and len([d for d in Path(TOMATO_DIR).iterdir() if d.is_dir()]) >= 10:\n",
    "    print('[Skip] Tomato subset already prepared at', TOMATO_DIR)\n",
    "else:\n",
    "    print('[Build] Creating tomato subset at', TOMATO_DIR)\n",
    "    shutil.rmtree(TOMATO_DIR, ignore_errors=True)\n",
    "    os.makedirs(TOMATO_DIR, exist_ok=True)\n",
    "    for d in sorted(Path(SRC_DIR).glob('Tomato___*')):\n",
    "        if d.is_dir():\n",
    "            shutil.copytree(str(d), str(Path(TOMATO_DIR)/d.name))\n",
    "print('[Sanity] Classes in tomato subset:')\n",
    "for n in sorted(os.listdir(TOMATO_DIR)):\n",
    "    print(' -', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c17f1",
   "metadata": {
    "id": "788c17f1"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63749d3a",
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1770835994029,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "63749d3a"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH = 32\n",
    "NUM_WORKERS = 2\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "test_split_ratio = 0.15 # 85/15 ratio\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "data_root = os.path.join(DATA_DIR, 'tomato_full')\n",
    "train_dataset = datasets.ImageFolder(root=data_root, transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(root=data_root, transform=test_transforms)\n",
    "\n",
    "labels = train_dataset.targets\n",
    "label_names = train_dataset.classes\n",
    "\n",
    "# # Dataloader\n",
    "# train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "# test_loader  = DataLoader(test_data,  batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd733d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1770835994056,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "afd733d0",
    "outputId": "b482f300-1caf-45a1-f7c1-a562fda22011"
   },
   "outputs": [],
   "source": [
    "# REQUIRED: Fill in these metadata fields\n",
    "dataset_name = \"PlantVillage — Tomato subset (10 classes)\"\n",
    "dataset_source = \"https://github.com/gabrieldgf4/PlantVillage-Dataset.git\"\n",
    "n_samples = len(labels)  # Total number of images\n",
    "n_classes = len(np.unique(labels))  # Number of classes\n",
    "samples_per_class = [{train_dataset.classes[label]: labels.count(label)} for label in np.unique(labels) ]\n",
    "image_shape = [224, 224, 3]  # [height, width, channels]\n",
    "problem_type = \"classification\"\n",
    "\n",
    "# Primary metric selection\n",
    "primary_metric = 'accuracy'\n",
    "metric_justification = ('Accuracy is appropriate because classes are relatively balanced and images are curated; '\n",
    "                       'for safety-critical deployments we would prefer recall to reduce false negatives.')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Source: {dataset_source}\")\n",
    "print(f\"Total Samples: {n_samples}\")\n",
    "print(f\"Number of Classes: {n_classes}\")\n",
    "print(f\"Samples per Class: {samples_per_class}\")\n",
    "print(f\"Image Shape: {image_shape}\")\n",
    "print(f\"Primary Metric: {primary_metric}\")\n",
    "print(f\"Metric Justification: {metric_justification}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7c46d",
   "metadata": {
    "id": "6dc7c46d"
   },
   "source": [
    "## 1.2 Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3556a93",
   "metadata": {
    "id": "a3556a93"
   },
   "source": [
    "### Sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa9c2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338,
     "output_embedded_package_id": "154p4udS3BxpSICBf1i7jS2U5r7rfsXKB"
    },
    "executionInfo": {
     "elapsed": 1977,
     "status": "ok",
     "timestamp": 1770835996035,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "d1aa9c2d",
    "outputId": "9deefe81-ea15-40e6-bd03-f02df675aaf8"
   },
   "outputs": [],
   "source": [
    "# Show sample images from each class\n",
    "print(\"Sample images from each classes\")\n",
    "class_samples = {}\n",
    "for idx, label in enumerate(labels):\n",
    "    if label not in class_samples:\n",
    "        class_samples[label] = idx\n",
    "    if len(class_samples) == n_classes:\n",
    "        break\n",
    "\n",
    "# Create a grid to display sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (label_idx, sample_idx) in enumerate(sorted(class_samples.items())):\n",
    "    # Load image without transforms to show original\n",
    "    img_path = train_dataset.imgs[sample_idx][0]\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'{label_names[label_idx]}', fontsize=10, wrap=True)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2630749f",
   "metadata": {
    "id": "2630749f"
   },
   "source": [
    "### Plot class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae939979",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1770835996077,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "ae939979",
    "outputId": "fef8462e-53f7-4b98-e403-7d0ec18e1cc3"
   },
   "outputs": [],
   "source": [
    "class_counts = [labels.count(i) for i in range(n_classes)]\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(range(n_classes), class_counts, color='steelblue', alpha=0.8)\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Number of Images', fontsize=12)\n",
    "plt.title('Distribution of images across classes', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(n_classes), [name.replace('Tomato___', '').replace('_', ' ') for name in label_names],\n",
    "           rotation=90, ha='right', fontsize=9)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf1ed1",
   "metadata": {
    "id": "e0cf1ed1"
   },
   "source": [
    "### Display image statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf863ae8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1770835996084,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "cf863ae8",
    "outputId": "92ead621-ecf2-4996-95ad-42261925814e"
   },
   "outputs": [],
   "source": [
    "sample_img = Image.open(train_dataset.imgs[0][0])\n",
    "print(f\"Sample Image Size: {sample_img.size}\")\n",
    "print(f\"Sample Image Mode: {sample_img.mode}\")\n",
    "print(f\"Target Image Size (after preprocessing): {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Normalization Mean: {mean}\")\n",
    "print(f\"Normalization Std: {std}\")\n",
    "print(f\"Total Samples: {n_samples}\")\n",
    "print(f\"Number of Classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing_section",
   "metadata": {
    "id": "preprocessing_section"
   },
   "source": [
    "## 1.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing_code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1770835996091,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "preprocessing_code",
    "outputId": "6a895314-334c-4a7a-8781-07751e4046da"
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing and Train/Test Split\n",
    "# Images are resized to 224x224 and normalized using ImageNet statistics\n",
    "# Train/Test split: 85/15 with stratification to maintain class balance\n",
    "\n",
    "SPLIT_CHOICE = \"85_15\"\n",
    "train_test_ratio = 0.1 if SPLIT_CHOICE=='90_10' else 0.15\n",
    "custom_batch_size = 32\n",
    "\n",
    "\n",
    "# Train and test transforms takes care of data processing,\n",
    "# copied down here for to have one more look at it\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomRotation(10),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std),\n",
    "# ])\n",
    "# test_transforms = transforms.Compose([\n",
    "#     transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std),\n",
    "# ])\n",
    "\n",
    "train_index, test_index = train_test_split(\n",
    "    range(len(labels)),\n",
    "    test_size=train_test_ratio,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "train_data = Subset(train_dataset, train_index)\n",
    "test_data  = Subset(test_dataset,  test_index)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=32, shuffle=False)\n",
    "\n",
    "train_samples = len(train_data)\n",
    "test_samples = len(test_data)\n",
    "\n",
    "print(f\"\\nTrain/Test Split: {train_test_ratio}\")\n",
    "print(f\"Training Samples: {train_samples}\")\n",
    "print(f\"Test Samples: {test_samples}\")\n",
    "print(f\"Batch Size: {custom_batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5fda5e",
   "metadata": {
    "id": "ed5fda5e"
   },
   "source": [
    "# Part 2: Custom CNN Implementation\n",
    "================================================================================\n",
    "PART 2: CUSTOM CNN IMPLEMENTATION (5 MARKS)\n",
    "================================================================================\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Build CNN using Keras/PyTorch layers\n",
    "- Architecture must include:\n",
    "  * Conv2D layers (at least 2)\n",
    "  * Pooling layers (MaxPool or AvgPool)\n",
    "  * Global Average Pooling (GAP) - MANDATORY\n",
    "  * Output layer (Softmax for multi-class)\n",
    "- Use model.compile() and model.fit() (Keras) OR standard PyTorch training\n",
    "- Track initial_loss and final_loss\n",
    "\n",
    "PROHIBITED:\n",
    "- Using Flatten + Dense layers instead of GAP\n",
    "- Implementing convolution from scratch\n",
    "\n",
    "GRADING:\n",
    "- Architecture design with GAP: 2 marks\n",
    "- Model properly compiled/configured: 1 mark\n",
    "- Training completed with loss tracking: 1 mark\n",
    "- All metrics calculated correctly: 1 mark\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff31b5f",
   "metadata": {
    "id": "4ff31b5f"
   },
   "source": [
    "### 2.1 Custom CNN Architecture Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf15be",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770835996095,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "c0cf15be"
   },
   "outputs": [],
   "source": [
    "def build_custom_cnn(input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Build custom CNN architecture\n",
    "\n",
    "    Args:\n",
    "        input_shape: tuple (height, width, channels)\n",
    "        n_classes: number of output classes\n",
    "\n",
    "    Returns:\n",
    "        model: compiled CNN model\n",
    "    \"\"\"\n",
    "    class CustomCNN(nn.Module):\n",
    "        def __init__(self, input_shape, num_classes):\n",
    "            super(CustomCNN, self).__init__()\n",
    "            in_channels = input_shape[-1]\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(32,32,3,padding=1), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2) # 224->112\n",
    "            )\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(32,64,3,padding=1), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64,64,3,padding=1), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2) # 112->56\n",
    "            )\n",
    "            self.conv3 = nn.Sequential(\n",
    "                nn.Conv2d(64,128,3,padding=1), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128,128,3,padding=1), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2) # 56->28\n",
    "            )\n",
    "            self.class_conv = nn.Conv2d(128, num_classes, kernel_size=1, bias=True)\n",
    "            self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x); x = self.conv2(x); x = self.conv3(x)\n",
    "            x = self.class_conv(x)\n",
    "            x = self.gap(x)\n",
    "            x = x.flatten(1) # (N, num_classes) raw logits\n",
    "            return x\n",
    "\n",
    "    return CustomCNN(input_shape, n_classes).to(device)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03d777",
   "metadata": {
    "id": "6f03d777"
   },
   "source": [
    "#### Create model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519293b",
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1770835996182,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "9519293b"
   },
   "outputs": [],
   "source": [
    "model_cnn = build_custom_cnn(image_shape, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7cdb2e",
   "metadata": {
    "id": "cd7cdb2e"
   },
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a1e2a",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770835996184,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "8e3a1e2a"
   },
   "outputs": [],
   "source": [
    "custom_learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=custom_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056549e",
   "metadata": {
    "id": "3056549e"
   },
   "source": [
    "### 2.2 Train Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CUSTOM CNN TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# TensorBoard writers\n",
    "writer_cnn = SummaryWriter(log_dir=os.path.join(LOG_DIR, 'model_cnn'))\n",
    "\n",
    "# Track training time\n",
    "custom_cnn_start_time = time.time()\n",
    "\n",
    "# Train your model\n",
    "EPOCHS = 10\n",
    "\n",
    "initial_loss_value = None\n",
    "final_loss_value = None\n",
    "\n",
    "# --- ADDED: Lists to store all metrics for the history ---\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # 1. TRAINING (Your existing logic)\n",
    "    model_cnn.train()\n",
    "    running_loss, running_correct, running_total = 0.0, 0, 0\n",
    "    \n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model_cnn(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        running_correct += (preds==labels).sum().item()\n",
    "        running_total += labels.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc  = running_correct / max(1, running_total)\n",
    "    \n",
    "    # 2. VALIDATION (Added: Required for the plots)\n",
    "    model_cnn.eval()\n",
    "    val_running_loss, val_running_correct, val_running_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits = model_cnn(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "            val_running_loss += loss.item() * imgs.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            val_running_correct += (preds==labels).sum().item()\n",
    "            val_running_total += labels.size(0)\n",
    "            \n",
    "    val_epoch_loss = val_running_loss / len(test_loader.dataset)\n",
    "    val_epoch_acc = val_running_correct / max(1, val_running_total)\n",
    "\n",
    "    # 3. STORAGE (Added: Save to lists)\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accs.append(val_epoch_acc)\n",
    "\n",
    "    # Your existing logging logic\n",
    "    if epoch == 1: initial_loss_value = epoch_loss\n",
    "    final_loss_value = epoch_loss\n",
    "    \n",
    "    writer_cnn.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "    writer_cnn.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "    # Added validation logging to tensorboard too\n",
    "    writer_cnn.add_scalar('Loss/val', val_epoch_loss, epoch)\n",
    "    writer_cnn.add_scalar('Accuracy/val', val_epoch_acc, epoch)\n",
    "\n",
    "    custom_cnn_training_time = time.time() - custom_cnn_start_time\n",
    "    print(f'[ModelCNN] Epoch {epoch}/{EPOCHS} - '\n",
    "          f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | '\n",
    "          f'Val Loss: {val_epoch_loss:.4f} Val Acc: {val_epoch_acc:.4f}')\n",
    "\n",
    "custom_cnn_training_time = time.time() - custom_cnn_start_time\n",
    "custom_cnn_initial_loss = initial_loss_value\n",
    "custom_cnn_final_loss = final_loss_value\n",
    "\n",
    "print(f\"Training completed in {custom_cnn_training_time:.2f} seconds\")\n",
    "print(f\"Initial Loss: {custom_cnn_initial_loss:.4f}\")\n",
    "print(f\"Final Loss: {custom_cnn_final_loss:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# --- ADDED: Create the history dictionary expected by the plot function ---\n",
    "custom_history = {\n",
    "    'train_loss': train_losses,\n",
    "    'train_acc': train_accs,\n",
    "    'val_loss': val_losses,\n",
    "    'val_acc': val_accs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172bfe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model_cnn.parameters())\n",
    "trainable_params_custom = sum(p.numel() for p in model_cnn.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters: {total_params}\"\n",
    "      f\"\\nTrainable Parameters: {trainable_params_custom}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate custom CNN layers\n",
    "\n",
    "def count_layers(model):\n",
    "    num_conv = 0\n",
    "    num_pool = 0\n",
    "    \n",
    "    # model.modules() recursively returns every layer in the network\n",
    "    for layer in model.modules():\n",
    "        # Check for Convolutional layers\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            num_conv += 1\n",
    "            \n",
    "        # Check for Pooling layers (MaxPool, AvgPool, AdaptiveAvgPool)\n",
    "        elif isinstance(layer, (nn.MaxPool2d, nn.AvgPool2d, nn.AdaptiveAvgPool2d)):\n",
    "            num_pool += 1\n",
    "            \n",
    "    return num_conv, num_pool\n",
    "\n",
    "# 3. Get the results\n",
    "n_convs, n_pools = count_layers(model_cnn)\n",
    "\n",
    "print(f\"Number of Convolutional Layers: {n_convs}\")\n",
    "print(f\"Number of Pooling Layers:       {n_pools}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f4d8a",
   "metadata": {
    "id": "017f4d8a"
   },
   "source": [
    "### 2.3 Evaluate Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15d4ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10526,
     "status": "ok",
     "timestamp": 1770837647359,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "cc15d4ef",
    "outputId": "ebbeb3e2-f275-4e25-ba57-003f2bd69967"
   },
   "outputs": [],
   "source": [
    "model_cnn.eval()\n",
    "y_pred, y_test = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        logits = model_cnn(imgs)\n",
    "        p = logits.argmax(dim=1).cpu().numpy()\n",
    "        y_pred.extend(p)\n",
    "        y_test.extend(labels.numpy())\n",
    "\n",
    "# CRITICAL: These MUST be calculated from your actual results\n",
    "# DO NOT submit with 0.0 values - autograder will detect this\n",
    "# REQUIRED: Calculate all 4 metrics\n",
    "custom_cnn_accuracy = accuracy_score(y_test, y_pred)\n",
    "custom_cnn_precision = precision_score(y_test, y_pred, average='macro')\n",
    "custom_cnn_recall = recall_score(y_test, y_pred, average='macro')\n",
    "custom_cnn_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "cnn_results = {\n",
    "    'initial_loss': float(initial_loss_value),\n",
    "    'final_loss': float(final_loss_value),\n",
    "    'training_time': float(custom_cnn_training_time),\n",
    "    'accuracy': float(custom_cnn_accuracy),\n",
    "    'precision': float(custom_cnn_precision),\n",
    "    'recall': float(custom_cnn_recall),\n",
    "    'f1': float(custom_cnn_f1),\n",
    "}\n",
    "\n",
    "print(\"\\nModel CNN Performance:\")\n",
    "print(f\"Accuracy:  {custom_cnn_accuracy:.4f}\")\n",
    "print(f\"Precision: {custom_cnn_precision:.4f}\")\n",
    "print(f\"Recall:    {custom_cnn_recall:.4f}\")\n",
    "print(f\"F1-Score:  {custom_cnn_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd52890",
   "metadata": {
    "id": "fcd52890"
   },
   "source": [
    "## 2.4 Visualize Custom CNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_training_history(history, title=\"Model Training Results\"):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy and loss.\n",
    "    Args:\n",
    "        history: dict with keys 'train_loss', 'train_acc', 'val_loss', 'val_acc'\n",
    "        title: str, title of the plot\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # --- Plot 1: Loss ---\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r--', label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Loss Evolution')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # --- Plot 2: Accuracy ---\n",
    "    ax2.plot(epochs, history['train_acc'], 'g-', label='Training Accuracy', linewidth=2)\n",
    "    ax2.plot(epochs, history['val_acc'], 'orange', linestyle='--', label='Validation Accuracy', linewidth=2)\n",
    "    ax2.set_title('Accuracy Evolution')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend(loc='lower right')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_training_history(custom_history, \"Custom CNN Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d127ad7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1770837652847,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "5d127ad7",
    "outputId": "d4d5fb07-c292-4aeb-977c-b5e6ce09934e"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot confusion matrix\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(confusion_matrix_result / np.maximum(confusion_matrix_result.sum(axis=1, keepdims=True),1), cmap='viridis', cbar=True)\n",
    "plt.title('Model CNN — Confusion Matrix (normalized)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ddb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Show sample predictions\n",
    "def visualize_predictions(model, dataloader, class_names, num_images=10):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # We need to un-normalize images to display them correctly\n",
    "    # Assuming mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225]\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = plt.subplot(2, 5, i + 1)\n",
    "        \n",
    "        # Convert tensor to numpy image\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        img = std * img + mean # Un-normalize\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        predicted_label = class_names[preds[i]]\n",
    "        true_label = class_names[labels[i]]\n",
    "        \n",
    "        color = 'green' if predicted_label == true_label else 'red'\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Pred: {predicted_label}\\nTrue: {true_label}\", color=color)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "# Usage Example:\n",
    "visualize_predictions(model_cnn, test_loader, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7cc782",
   "metadata": {
    "id": "0b7cc782"
   },
   "source": [
    "================================================================================\n",
    "PART 3: TRANSFER LEARNING IMPLEMENTATION (5 MARKS)\n",
    "================================================================================\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Use pre-trained model: ResNet18/ResNet50 OR VGG16/VGG19\n",
    "- Freeze base layers (feature extractor)\n",
    "- Replace final layers with:\n",
    "  * Global Average Pooling (GAP) - MANDATORY\n",
    "  * Custom classification head\n",
    "- Fine-tune on your dataset\n",
    "- Track initial_loss and final_loss\n",
    "\n",
    "GRADING:\n",
    "- Valid base model with frozen layers: 2 marks\n",
    "- GAP + custom head properly implemented: 1 mark\n",
    "- Training completed with loss tracking: 1 mark\n",
    "- All metrics calculated correctly: 1 mark\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JO1_MO7qKiDt",
   "metadata": {
    "id": "JO1_MO7qKiDt"
   },
   "source": [
    "## 3.1 Load Pre-trained Model and Modify Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfea1ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1770838024062,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "8dfea1ab",
    "outputId": "81ffb3f4-a797-4318-c773-809e99770c13"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFER LEARNING IMPLEMENTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# load pre-trained model\n",
    "pretrained_model_name = \"ResNet18\"\n",
    "writer_tl  = SummaryWriter(log_dir=os.path.join(LOG_DIR, 'resnet18_tl'))\n",
    "\n",
    "\n",
    "def build_transfer_learning_model(base_model_name, input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Build transfer learning model\n",
    "\n",
    "    Args:\n",
    "        base_model_name: string (ResNet18/ResNet50/VGG16/VGG19)\n",
    "        input_shape: tuple (height, width, channels)\n",
    "        n_classes: number of output classes\n",
    "\n",
    "    Returns:\n",
    "        model: compiled transfer learning model\n",
    "    \"\"\"\n",
    "    # Load pre-trained model without top layers\n",
    "    resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    # Freeze base layers\n",
    "    for p in resnet18.parameters():\n",
    "      p.requires_grad = False\n",
    "\n",
    "    class ResNet18_GAP(nn.Module):\n",
    "      def __init__(self, backbone, num_classes):\n",
    "          super().__init__()\n",
    "          self.features = nn.Sequential(\n",
    "              backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool,\n",
    "              backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4\n",
    "          )\n",
    "          self.class_conv = nn.Conv2d(512, num_classes, kernel_size=1, bias=True)\n",
    "          self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "          for p in self.features.parameters(): p.requires_grad = False\n",
    "          for p in self.class_conv.parameters(): p.requires_grad = True\n",
    "      def forward(self, x):\n",
    "          x = self.features(x)\n",
    "          x = self.class_conv(x)\n",
    "          x = self.gap(x)\n",
    "          x = x.flatten(1)\n",
    "          return x\n",
    "\n",
    "    return ResNet18_GAP(resnet18, num_classes=n_classes).to(device)\n",
    "\n",
    "def count_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    frozen = total - trainable\n",
    "    return total, trainable, frozen\n",
    "\n",
    "# TODO: Create transfer learning model\n",
    "transfer_model = build_transfer_learning_model(pretrained_model_name, image_shape, n_classes)\n",
    "criterion_tl = nn.CrossEntropyLoss()\n",
    "optimizer_tl = torch.optim.Adam(filter(lambda p: p.requires_grad, transfer_model.parameters()), lr=1e-3)\n",
    "\n",
    "\n",
    "# REQUIRED: Count layers and parameters\n",
    "total_parameters, trainable_parameters, frozen_params = count_params(transfer_model)\n",
    "frozen_layers = sum(1 for p in transfer_model.parameters() if p.requires_grad)  # TODO: Count frozen layers\n",
    "trainable_layers = sum(1 for p in transfer_model.parameters() if not p.requires_grad)  # TODO: Count trainable layers\n",
    "\n",
    "print(f\"Base Model: {pretrained_model_name}\")\n",
    "print(f\"Frozen Layers: {frozen_layers}\")\n",
    "print(f\"Trainable Layers: {trainable_layers}\")\n",
    "print(f\"Total Parameters: {total_parameters:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_parameters:,}\")\n",
    "print(f\"Using Global Average Pooling: YES\")\n",
    "print(f\"Optimizer: {optimizer_tl}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wOruk8zSKlIl",
   "metadata": {
    "id": "wOruk8zSKlIl"
   },
   "source": [
    "## 3.2 Train Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce248b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFER LEARNING (ResNet18) TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# TensorBoard writer for Transfer Learning\n",
    "writer_tl = SummaryWriter(log_dir=os.path.join(\"runs\", 'model_tl'))\n",
    "\n",
    "# Training configuration\n",
    "tl_learning_rate = 0.001\n",
    "tl_epochs = 10\n",
    "tl_batch_size = 32\n",
    "\n",
    "\n",
    "# Track training time\n",
    "tl_start_time = time.time()\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "tl_train_losses = []\n",
    "tl_train_accs = []\n",
    "tl_val_losses = []\n",
    "tl_val_accs = []\n",
    "\n",
    "initial_loss_tl = None\n",
    "final_loss_tl = None\n",
    "\n",
    "# Train model\n",
    "for epoch in range(1, tl_epochs+1):\n",
    "    transfer_model.train()\n",
    "    running_loss, running_correct, running_total = 0.0, 0, 0\n",
    "    \n",
    "    print(f\"\\nStarting Epoch {epoch}/{tl_epochs}...\")\n",
    "    \n",
    "    # --- TRAINING LOOP ---\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        # Ensure you use the specific optimizer for TL\n",
    "        optimizer_tl.zero_grad()\n",
    "        logits = transfer_model(imgs)\n",
    "        loss = criterion_tl(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer_tl.step()\n",
    "        \n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        running_total += labels.size(0)\n",
    "        \n",
    "        # Progress print every 20 batches\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"  Batch {i+1}/{len(train_loader)} - Current Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc  = running_correct / max(1, running_total)\n",
    "\n",
    "    # --- VALIDATION LOOP (Added) ---\n",
    "    transfer_model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    val_running_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits = transfer_model(imgs)\n",
    "            loss = criterion_tl(logits, labels)\n",
    "            \n",
    "            val_running_loss += loss.item() * imgs.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            val_running_correct += (preds == labels).sum().item()\n",
    "            val_running_total += labels.size(0)\n",
    "            \n",
    "    val_epoch_loss = val_running_loss / len(test_loader.dataset)\n",
    "    val_epoch_acc = val_running_correct / val_running_total\n",
    "    \n",
    "    # --- STORAGE & LOGGING ---\n",
    "    tl_train_losses.append(epoch_loss)\n",
    "    tl_train_accs.append(epoch_acc)\n",
    "    tl_val_losses.append(val_epoch_loss)\n",
    "    tl_val_accs.append(val_epoch_acc)\n",
    "    \n",
    "    if epoch == 1: initial_loss_tl = epoch_loss\n",
    "    final_loss_tl = epoch_loss\n",
    "    \n",
    "    writer_tl.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "    writer_tl.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "    writer_tl.add_scalar('Loss/val', val_epoch_loss, epoch)\n",
    "    writer_tl.add_scalar('Accuracy/val', val_epoch_acc, epoch)\n",
    "    \n",
    "    print(f'[ResNet18 TL] Epoch {epoch}/{tl_epochs} | '\n",
    "          f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | '\n",
    "          f'Val Loss: {val_epoch_loss:.4f} Val Acc: {val_epoch_acc:.4f}')\n",
    "\n",
    "# Final calculations\n",
    "tl_training_time = time.time() - tl_start_time\n",
    "tl_initial_loss = initial_loss_tl\n",
    "tl_final_loss = final_loss_tl\n",
    "writer_tl.flush()\n",
    "writer_tl.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Training completed in {tl_training_time:.2f} seconds\")\n",
    "print(f\"Initial Loss: {tl_initial_loss:.4f}\")\n",
    "print(f\"Final Loss: {tl_final_loss:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create the history dictionary needed for plotting\n",
    "transfer_history = {\n",
    "    'train_loss': tl_train_losses, 'train_acc': tl_train_accs,\n",
    "    'val_loss': tl_val_losses, 'val_acc': tl_val_accs\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0de85",
   "metadata": {},
   "source": [
    "## 3.3 Evaluate Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee0e97",
   "metadata": {
    "id": "b6ee0e97"
   },
   "outputs": [],
   "source": [
    "# 3.3 Evaluate Transfer Learning Model\n",
    "\n",
    "transfer_model.eval()\n",
    "y_pred, y_test = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        logits = transfer_model(imgs)\n",
    "        p = logits.argmax(dim=1).cpu().numpy()\n",
    "        y_pred.extend(p)\n",
    "        y_test.extend(labels.numpy())\n",
    "\n",
    "# REQUIRED: Calculate all 4 metrics\n",
    "tl_accuracy = accuracy_score(y_test, y_pred)\n",
    "tl_precision = precision_score(y_test, y_pred, average='macro')\n",
    "tl_recall = recall_score(y_test, y_pred, average='macro')\n",
    "tl_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"\\nTransfer Learning Performance:\")\n",
    "print(f\"Accuracy:  {tl_accuracy:.4f}\")\n",
    "print(f\"Precision: {tl_precision:.4f}\")\n",
    "print(f\"Recall:    {tl_recall:.4f}\")\n",
    "print(f\"F1-Score:  {tl_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zSy9v7_oMfW_",
   "metadata": {
    "id": "zSy9v7_oMfW_"
   },
   "source": [
    "### 3.4 Visualize Transfer Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3uwr-H_aMcWo",
   "metadata": {
    "id": "3uwr-H_aMcWo"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot training curves (loss and accuracy)\n",
    "plot_training_history(transfer_history, \"Transfer Learning (ResNet18) Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f361d22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "error",
     "timestamp": 1770838469217,
     "user": {
      "displayName": "MANODHAYAN K",
      "userId": "01082090040325553631"
     },
     "user_tz": -330
    },
    "id": "6f361d22",
    "outputId": "4b39ae4f-a217-414d-939d-25ea697ffd2a"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(cm/np.maximum(cm.sum(axis=1, keepdims=True),1), cmap='viridis', cbar=True)\n",
    "plt.title('ResNet18 TL — Confusion Matrix (normalized)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bcdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Show sample predictions\n",
    "visualize_predictions(transfer_model, test_loader, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79df6f",
   "metadata": {
    "id": "0f79df6f"
   },
   "source": [
    "# 4. Model Comparison and Visualization\n",
    "================================================================================\n",
    "PART 4: MODEL COMPARISON AND VISUALIZATION (Informational)\n",
    "================================================================================\n",
    "\n",
    "Compare both models on:\n",
    "- Performance metrics\n",
    "- Training time\n",
    "- Model complexity\n",
    "- Convergence behavior\n",
    "\n",
    "================================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc71486",
   "metadata": {},
   "source": [
    "## 4.1 Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c7025",
   "metadata": {
    "id": "913c7025"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time (s)', 'Parameters'],\n",
    "    'Custom CNN': [\n",
    "        custom_cnn_accuracy,\n",
    "        custom_cnn_precision,\n",
    "        custom_cnn_recall,\n",
    "        custom_cnn_f1,\n",
    "        custom_cnn_training_time,\n",
    "        trainable_params_custom\n",
    "    ],\n",
    "    'Transfer Learning': [\n",
    "        tl_accuracy,\n",
    "        tl_precision,\n",
    "        tl_recall,\n",
    "        tl_f1,\n",
    "        tl_training_time,\n",
    "        trainable_parameters\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857a54b",
   "metadata": {},
   "source": [
    "## 4.2 Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create bar plot comparing metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data Preparation\n",
    "# Assuming variables: cnn_accuracy, cnn_precision, cnn_recall, cnn_f1\n",
    "# and: tl_accuracy, tl_precision, tl_recall, tl_f1 exist from previous cells.\n",
    "# If not, replace these variables with the raw numbers from your table.\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "cnn_scores = [custom_cnn_accuracy, custom_cnn_precision, custom_cnn_recall, custom_cnn_f1]\n",
    "tl_scores = [tl_accuracy, tl_precision, tl_recall, tl_f1]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, cnn_scores, width, label='Custom CNN', color='skyblue')\n",
    "rects2 = ax.bar(x + width/2, tl_scores, width, label='Transfer Learning', color='orange')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.set_ylim(0, 1.1) # Extend y-axis slightly for labels\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Function to add labels on top of bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training curves comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_comparison_curves(hist1, hist2, name1=\"Custom CNN\", name2=\"Transfer Learning\"):\n",
    "    epochs = range(1, len(hist1['train_loss']) + 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # --- Plot 1: Validation Accuracy Comparison ---\n",
    "    ax1.plot(epochs, hist1['val_acc'], 'b-o', label=f'{name1} Val Acc', linewidth=2)\n",
    "    ax1.plot(epochs, hist2['val_acc'], 'r-s', label=f'{name2} Val Acc', linewidth=2)\n",
    "    # Optional: Add Training Acc as dashed lines\n",
    "    ax1.plot(epochs, hist1['train_acc'], 'b--', alpha=0.3, label=f'{name1} Train Acc')\n",
    "    ax1.plot(epochs, hist2['train_acc'], 'r--', alpha=0.3, label=f'{name2} Train Acc')\n",
    "    \n",
    "    ax1.set_title('Accuracy Comparison')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # --- Plot 2: Validation Loss Comparison ---\n",
    "    ax1.plot(epochs, hist1['val_loss'], 'b-o', label=f'{name1} Val Loss', linewidth=2)\n",
    "    ax1.plot(epochs, hist2['val_loss'], 'r-s', label=f'{name2} Val Loss', linewidth=2)\n",
    "    # Optional: Add Training Loss as dashed lines\n",
    "    ax2.plot(epochs, hist1['train_loss'], 'b--', alpha=0.3, label=f'{name1} Train Loss')\n",
    "    ax2.plot(epochs, hist2['train_loss'], 'r--', alpha=0.3, label=f'{name2} Train Loss')\n",
    "\n",
    "    ax2.set_title('Loss Comparison')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.suptitle(f\"Training Dynamics: {name1} vs {name2}\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "# Execute Plot\n",
    "plot_comparison_curves(custom_history, transfer_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb502b",
   "metadata": {
    "id": "05bb502b"
   },
   "outputs": [],
   "source": [
    "# TODO: Create side-by-side confusion matrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "def get_all_preds(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            logits = model(imgs)\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# 1. Get Predictions\n",
    "print(\"Generating predictions for Custom CNN...\")\n",
    "y_true, y_pred_cnn = get_all_preds(model_cnn, test_loader)\n",
    "\n",
    "print(\"Generating predictions for Transfer Learning...\")\n",
    "_, y_pred_tl = get_all_preds(transfer_model, test_loader)\n",
    "\n",
    "# 2. Compute Confusion Matrices\n",
    "cm_cnn = confusion_matrix(y_true, y_pred_cnn)\n",
    "cm_tl = confusion_matrix(y_true, y_pred_tl)\n",
    "\n",
    "# 3. Plot Side-by-Side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "class_labels = train_dataset.classes # Assuming this exists from your dataset\n",
    "\n",
    "# Custom CNN Heatmap\n",
    "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "axes[0].set_title('Custom CNN Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "# Transfer Learning Heatmap\n",
    "sns.heatmap(cm_tl, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "axes[1].set_title('Transfer Learning Confusion Matrix')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ba186",
   "metadata": {
    "id": "087ba186"
   },
   "source": [
    "# 5. Analysis\n",
    "================================================================================\n",
    "PART 5: ANALYSIS (2 MARKS)\n",
    "================================================================================\n",
    "\n",
    "REQUIRED:\n",
    "- Write MAXIMUM 200 words (guideline - no marks deduction if exceeded)\n",
    "- Address key topics with depth\n",
    "\n",
    "GRADING (Quality-based):\n",
    "- Covers 5+ key topics with deep understanding: 2 marks\n",
    "- Covers 3-4 key topics with good understanding: 1 mark\n",
    "- Covers <3 key topics or superficial: 0 marks\n",
    "\n",
    "Key Topics:\n",
    "1. Performance comparison with specific metrics\n",
    "2. Pre-training vs training from scratch impact\n",
    "3. GAP effect on performance/overfitting\n",
    "4. Computational cost comparison\n",
    "5. Transfer learning insights\n",
    "6. Convergence behavior differences\n",
    "================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb819a",
   "metadata": {
    "id": "5cfb819a"
   },
   "outputs": [],
   "source": [
    "analysis_text = \"\"\"\n",
    "TODO: Write your analysis here (maximum 200 words guideline)\n",
    "\n",
    "Address:\n",
    "1. Which model performed better and by how much?\n",
    "   Custom CNN performed better (Accuracy = 94.3% vs 92.6%), likely due to being tailored to the dataset and having more trainable parameters.\n",
    "\n",
    "2. Impact of pre-training vs training from scratch?\n",
    "   End-to-end training allowed the Custom CNN to learn dataset-specific features.\n",
    "   Generic, fixed feature maps trained on ImageNet may not have captured the nuances of plant disease patterns, limiting the transfer learning model's performance.\n",
    "\n",
    "3. Effect of Global Average Pooling?\n",
    "   The impact of Global Average Pooling (GAP) was significant. \n",
    "   By reducing spatial dimensions to 1 x 1 without heavy fully connected layers, GAP minimized parameter bloat and prevented overfitting, allowing the Custom CNN to generalize well despite having ~288,000 parameters.\n",
    "\n",
    "4. Computational cost comparison?\n",
    "   Custom CNN:\n",
    "   Training Time: Approximately 1271.22 seconds\n",
    "   Parameters: 288298\n",
    "   Transfer learning based CNN:\n",
    "   Training Time: Approximately 1227.61 seconds\n",
    "   Parameters: 5130\n",
    "\n",
    "5. Insights about transfer learning?\n",
    "   Transfer Learning offers excellent performance with minimal trainable parameters, making it ideal for limited data. \n",
    "   However, for specialized datasets with sufficient training examples, a well-designed Custom CNN with GAP can marginally surpass generic pre-trained models.\n",
    "\"\"\"\n",
    "\n",
    "# REQUIRED: Print analysis with word count\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(analysis_text)\n",
    "print(\"=\"*70)\n",
    "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
    "if len(analysis_text.split()) > 200:\n",
    "    print(\"⚠️  Warning: Analysis exceeds 200 words (guideline)\")\n",
    "else:\n",
    "    print(\"✓ Analysis within word count guideline\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b17350",
   "metadata": {
    "id": "06b17350"
   },
   "source": [
    "# 6. RESULTS SUMMARY\n",
    "\n",
    "================================================================================\n",
    "PART 6: ASSIGNMENT RESULTS SUMMARY (REQUIRED FOR AUTO-GRADING)\n",
    "================================================================================\n",
    "\n",
    "DO NOT MODIFY THE STRUCTURE BELOW\n",
    "This JSON output is used by the auto-grader\n",
    "Ensure all field names are EXACT\n",
    "================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f8574",
   "metadata": {
    "id": "c22f8574"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_assignment_results():\n",
    "    \"\"\"\n",
    "    Generate complete assignment results in required format\n",
    "\n",
    "    Returns:\n",
    "        dict: Complete results with all required fields\n",
    "    \"\"\"\n",
    "\n",
    "    framework_used = \"pytorch\"\n",
    "\n",
    "    results = {\n",
    "        # Dataset Information\n",
    "        'dataset_name': dataset_name,\n",
    "        'dataset_source': dataset_source,\n",
    "        'n_samples': n_samples,\n",
    "        'n_classes': n_classes,\n",
    "        'samples_per_class': samples_per_class,\n",
    "        'image_shape': image_shape,\n",
    "        'problem_type': problem_type,\n",
    "        'primary_metric': primary_metric,\n",
    "        'metric_justification': metric_justification,\n",
    "        'train_samples': train_samples,\n",
    "        'test_samples': test_samples,\n",
    "        'train_test_ratio': train_test_ratio,\n",
    "\n",
    "        # Custom CNN Results\n",
    "        'custom_cnn': {\n",
    "            'framework': framework_used,\n",
    "            'architecture': {\n",
    "                'conv_layers': n_convs,\n",
    "                'pooling_layers': n_pools,\n",
    "                'has_global_average_pooling': True,  # MUST be True\n",
    "                'output_layer': 'softmax',\n",
    "                'total_parameters': trainable_params_custom\n",
    "            },\n",
    "            'training_config': {\n",
    "                'learning_rate': custom_learning_rate,\n",
    "                'n_epochs': EPOCHS,\n",
    "                'batch_size': custom_batch_size,\n",
    "                'optimizer': optimizer.__class__.__name__,\n",
    "                'loss_function': 'categorical_crossentropy'\n",
    "            },\n",
    "            'initial_loss': custom_cnn_initial_loss,\n",
    "            'final_loss': custom_cnn_final_loss,\n",
    "            'training_time_seconds': custom_cnn_training_time,\n",
    "            'accuracy': custom_cnn_accuracy,\n",
    "            'precision': custom_cnn_precision,\n",
    "            'recall': custom_cnn_recall,\n",
    "            'f1_score': custom_cnn_f1\n",
    "        },\n",
    "\n",
    "        # Transfer Learning Results\n",
    "        'transfer_learning': {\n",
    "            'framework': framework_used,\n",
    "            'base_model': pretrained_model_name,\n",
    "            'frozen_layers': frozen_layers,\n",
    "            'trainable_layers': trainable_layers,\n",
    "            'has_global_average_pooling': True,  # MUST be True\n",
    "            'total_parameters': total_parameters,\n",
    "            'trainable_parameters': trainable_parameters,\n",
    "            'training_config': {\n",
    "                'learning_rate': tl_learning_rate,\n",
    "                'n_epochs': tl_epochs,\n",
    "                'batch_size': tl_batch_size,\n",
    "                'optimizer': optimizer_tl.__class__.__name__,  # Get the class name of the optimizer\n",
    "                'loss_function': 'categorical_crossentropy'\n",
    "            },\n",
    "            'initial_loss': tl_initial_loss,\n",
    "            'final_loss': tl_final_loss,\n",
    "            'training_time_seconds': tl_training_time,\n",
    "            'accuracy': tl_accuracy,\n",
    "            'precision': tl_precision,\n",
    "            'recall': tl_recall,\n",
    "            'f1_score': tl_f1\n",
    "        },\n",
    "\n",
    "        # Analysis\n",
    "        'analysis': analysis_text,\n",
    "        'analysis_word_count': len(analysis_text.split()),\n",
    "\n",
    "        # Training Success Indicators\n",
    "        'custom_cnn_loss_decreased': custom_cnn_final_loss < custom_cnn_initial_loss if custom_cnn_initial_loss and custom_cnn_final_loss else False,\n",
    "        'transfer_learning_loss_decreased': tl_final_loss < tl_initial_loss if tl_initial_loss and tl_final_loss else False,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Generate and print results\n",
    "try:\n",
    "    assignment_results = get_assignment_results()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(json.dumps(assignment_results, indent=2))\n",
    "    print(\"=\"*70)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️  ERROR generating results: {str(e)}\")\n",
    "    print(\"Please ensure all variables are properly defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d3b0e2",
   "metadata": {
    "id": "13d3b0e2"
   },
   "source": [
    "\n",
    "\"\"\"\n",
    "================================================================================\n",
    "ENVIRONMENT VERIFICATION - SCREENSHOT REQUIRED\n",
    "================================================================================\n",
    "\n",
    "IMPORTANT: Take a screenshot of your environment showing account details\n",
    "\n",
    "For Google Colab:\n",
    "- Click on your profile icon (top right)\n",
    "- Screenshot should show your email/account clearly\n",
    "- Include the entire Colab interface with notebook name visible\n",
    "\n",
    "For BITS Virtual Lab:\n",
    "- Screenshot showing your login credentials/account details\n",
    "- Include the entire interface with your username/session info visible\n",
    "\n",
    "Paste the screenshot below this cell or in a new markdown cell.\n",
    "This helps verify the work was done by you in your environment.\n",
    "\n",
    "================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed39d2b",
   "metadata": {
    "id": "7ed39d2b"
   },
   "outputs": [],
   "source": [
    "# Display system information\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENVIRONMENT INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n⚠️  REQUIRED: Add screenshot of your Google Colab/BITS Virtual Lab\")\n",
    "print(\"showing your account details in the cell below this one.\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1494b",
   "metadata": {
    "id": "37d1494b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "================================================================================\n",
    "FINAL CHECKLIST - VERIFY BEFORE SUBMISSION\n",
    "================================================================================\n",
    "\n",
    "□ Student information filled at the top (BITS ID, Name, Email)\n",
    "□ Filename is <BITS_ID>_cnn_assignment.ipynb\n",
    "□ All cells executed (Kernel → Restart & Run All)\n",
    "□ All outputs visible\n",
    "□ Custom CNN implemented with Global Average Pooling (NO Flatten+Dense)\n",
    "□ Transfer learning implemented with GAP\n",
    "□ Both models use Keras or PyTorch (NOT from scratch)\n",
    "□ Both models trained with loss tracking (initial_loss and final_loss)\n",
    "□ All 4 metrics calculated for both models\n",
    "□ Primary metric selected and justified\n",
    "□ Analysis written (quality matters, not just word count)\n",
    "□ Visualizations created\n",
    "□ Assignment results JSON printed at the end\n",
    "□ No execution errors in any cell\n",
    "□ File opens without corruption\n",
    "□ Submit ONLY .ipynb file (NO zip, NO data files, NO images)\n",
    "□ Only one submission attempt\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
